{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "bqodu7APW0zN"
   },
   "source": [
    "## Task 1 (5 points)\n",
    "\n",
    "Consider the vowel reconstruction task -- i.e. inserting missing vowels (aeuioy) to obtain proper English text. For instance for the input sentence:\n",
    "\n",
    "<pre>\n",
    "h m gd smbd hs stln ll m vwls\n",
    "</pre>\n",
    "\n",
    "the best result is\n",
    "\n",
    "<pre>\n",
    "oh my god somebody has stolen all my vowels\n",
    "</pre>\n",
    "\n",
    "In this task both dev and test data come from the two books about Winnie-the-Pooh. You have to train two RNN Language Models on *pooh-train.txt*. For the first model use the code below, for the second choose different hyperparameters (different dropout, smaller number of units or layers, or just do any modification you want).\n",
    "\n",
    "You can assume that only words from pooh_words.txt can occur in the reconstructed text. For decoding you have two options (choose one, or implement both ang get **+1** bonus point)\n",
    "\n",
    "1. Sample reconstructed text several times (with quite a low temperature), choose the most likely result.\n",
    "2. Perform beam search.\n",
    "\n",
    "Of course in the sampling procedure you should consider only words matching the given consonants.\n",
    "\n",
    "Report accuracy of your methods (for both language models). The accuracy should be computed by the following function, it should be *greater than 0.25*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "SEQUENCE_LENGTH = 15"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "zF2If6TqW0zO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class PoohDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequence_length, device):\n",
    "        txt = open('/content/sample_data/pooh_train.txt').read()\n",
    "\n",
    "        self.words = txt.lower().split()\n",
    "\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "        self.sequence_length = sequence_length\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length], device=self.device),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1], device=self.device))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kqpo5IYiW0zP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, n_vocab, device):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm_size = 512\n",
    "        self.embedding_dim = 100\n",
    "        self.num_layers = 2\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SJiloNJMW0zQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MyLSTMModel(nn.Module):\n",
    "    def __init__(self, n_vocab, device):\n",
    "        super(MyLSTMModel, self).__init__()\n",
    "        self.lstm_size = 512\n",
    "        self.embedding_dim = 256\n",
    "        self.num_layers = 3\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "alOUNR9MW0zR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(dataset, model):\n",
    "\n",
    "    batch_size = 512\n",
    "    max_epochs = 20\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(SEQUENCE_LENGTH)\n",
    "        losses = []\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "\n",
    "        print({ 'epoch': epoch, 'loss: ': np.array(losses).mean() })"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "xL7pou0MW0zS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "vowels = set(\"aoiuye'\")\n",
    "def devowelize(s):\n",
    "    rv = ''.join(a for a in s if a not in vowels)\n",
    "    if rv:\n",
    "        return rv\n",
    "    return '_' # Symbol for words without consonants\n",
    "\n",
    "pooh_words = set(open('/content/sample_data/pooh_words.txt').read().split())\n",
    "representation = dd(set)\n",
    "\n",
    "for w in pooh_words:\n",
    "    r = devowelize(w)\n",
    "    representation[r].add(w)\n",
    "\n",
    "hard_words = set()\n",
    "for r, ws in representation.items():\n",
    "    if len(ws) > 1:\n",
    "        hard_words.update(ws)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lNN96CWLW0zS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def reconstruct_sentence_1(model, sentence, dataset, t=1.0):\n",
    "    # using only last word\n",
    "    words = sentence\n",
    "    devowelized_sentence = [devowelize(w) for w in words]\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = model.init_state(1)\n",
    "\n",
    "    reconstructed = []\n",
    "    probabilities = []\n",
    "\n",
    "    matching = representation[devowelized_sentence[0]]\n",
    "    reconstructed.append(random.choice(list(matching)))\n",
    "\n",
    "    for i in range(len(devowelized_sentence) - 1):\n",
    "        try:\n",
    "            x = torch.tensor([[pooh_dataset.word_to_index[reconstructed[-1]]]])\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        x = x.to(device)\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "\n",
    "        matching = representation[devowelized_sentence[i + 1]]\n",
    "        try:\n",
    "            matching_idx = [pooh_dataset.word_to_index[match] for match in matching]\n",
    "        except KeyError:\n",
    "            reconstructed.append(random.choice(list(matching)))\n",
    "            continue\n",
    "        p = torch.nn.functional.softmax(last_word_logits/t, dim=0).detach().cpu().numpy()\n",
    "        p[~np.isin(np.arange(len(p)), matching_idx)] = 0\n",
    "        p = p/p.sum()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        reconstructed.append(dataset.index_to_word[word_index])\n",
    "        probabilities.append(p[word_index])\n",
    "    return reconstructed, probabilities"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "x2DjGc3QW0zS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def reconstruct_sentence_2(model, words, dataset, words_to_remember, t=1.0):\n",
    "    # using last words_to_remember\n",
    "    devowelized_sentence = [devowelize(w) for w in words]\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = model.init_state(words_to_remember)\n",
    "\n",
    "    reconstructed = words[:words_to_remember]\n",
    "    probabilities = []\n",
    "\n",
    "    for i in range(words_to_remember, len(devowelized_sentence)):\n",
    "        try:\n",
    "            x = torch.tensor([[pooh_dataset.word_to_index[word] for word in reconstructed[:words_to_remember]]])\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        x = x.to(device)\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "\n",
    "        matching = representation[devowelized_sentence[i]]\n",
    "        try:\n",
    "            matching_idx = [pooh_dataset.word_to_index[match] for match in matching]\n",
    "        except KeyError:\n",
    "            reconstructed.append(random.choice(list(matching)))\n",
    "            continue\n",
    "        p = torch.nn.functional.softmax(last_word_logits/t, dim=0).detach().cpu().numpy()\n",
    "        p[~np.isin(np.arange(len(p)), matching_idx)] = 0\n",
    "        p = p/p.sum()\n",
    "\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        reconstructed.append(dataset.index_to_word[word_index])\n",
    "        probabilities.append(p[word_index])\n",
    "    return reconstructed, probabilities"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "PFibGTe2W0zT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def accuracy(original_sequence, reconstructed_sequence):\n",
    "    sa = original_sequence\n",
    "    sb = reconstructed_sequence\n",
    "    score = len([1 for (a,b) in zip(sa, sb) if a == b])\n",
    "    return score / len(original_sequence)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ubMrhb_cW0zT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def sample_text(model, test_dataset, pooh_dataset, iters):\n",
    "    best_p, best_text = -np.inf, None\n",
    "    for _ in tqdm(range(iters)):\n",
    "        t, p = reconstruct_sentence_1(model, test_dataset, pooh_dataset)\n",
    "        if np.log(p).sum() > best_p:\n",
    "            best_p = np.log(p).sum()\n",
    "            best_text = t\n",
    "    return best_text, best_p"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "vNBY4bfwW0zU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "pooh_dataset = PoohDataset(SEQUENCE_LENGTH, device)\n",
    "test_dataset = open('/content/sample_data/pooh_test.txt').read()\n",
    "test_dataset = test_dataset.lower().split()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "r23MuQEYW0zU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 1"
   ],
   "metadata": {
    "collapsed": false,
    "id": "cdDiQ4AxW0zU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model = LSTMModel(len(pooh_dataset.uniq_words), device)\n",
    "model.to(device)\n",
    "# train(pooh_dataset, model)\n",
    "model.load_state_dict(torch.load('/content/sample_data/pooh_2x512_30ep.model'))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2prdpeaDW0zV",
    "outputId": "87b08e8c-b51e-4cd2-83e0-a7e75a9478e9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7759918356933282\n",
      "0.6648807245822171\n"
     ]
    }
   ],
   "source": [
    "reconstruction_1, prob_1 = reconstruct_sentence_1(model, test_dataset, pooh_dataset)\n",
    "reconstruction_2, prob_2 = reconstruct_sentence_2(model, test_dataset, pooh_dataset, words_to_remember=5)\n",
    "print(accuracy(test_dataset, reconstruction_1))\n",
    "print(accuracy(test_dataset, reconstruction_2))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufTcZRvQW0zV",
    "outputId": "c8925ce1-14ab-40e3-f5af-f4b60fee80e8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [01:25<00:00,  4.30s/it]\n"
     ]
    }
   ],
   "source": [
    "best_text, best_p = sample_text(model, test_dataset, pooh_dataset, 20)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjGFlqrbW0zV",
    "outputId": "622aa142-ebdd-4dd5-b756-5aab243426c7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7794361525704809"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "accuracy(test_dataset, best_text)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOxT9yrxW0zW",
    "outputId": "d8368116-77c0-43b6-c945-72c69a97cd0b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(best_p)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjfFUflFYGiC",
    "outputId": "0ed0c5fa-fbc9-4cad-b087-e725cd0347a9"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-1080.584\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 2"
   ],
   "metadata": {
    "collapsed": false,
    "id": "mbIaw9PaW0zW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'epoch': 0, 'loss: ': 5.699029926668134}\n",
      "{'epoch': 1, 'loss: ': 5.499392442535936}\n",
      "{'epoch': 2, 'loss: ': 5.486383848022997}\n",
      "{'epoch': 3, 'loss: ': 5.477660266976607}\n",
      "{'epoch': 4, 'loss: ': 5.47069087363126}\n",
      "{'epoch': 5, 'loss: ': 5.466182424311052}\n",
      "{'epoch': 6, 'loss: ': 5.462064868525455}\n",
      "{'epoch': 7, 'loss: ': 5.458349035497298}\n",
      "{'epoch': 8, 'loss: ': 5.4553016696059915}\n",
      "{'epoch': 9, 'loss: ': 5.452650664145486}\n",
      "{'epoch': 10, 'loss: ': 5.4497811417830615}\n",
      "{'epoch': 11, 'loss: ': 5.321557111907423}\n",
      "{'epoch': 12, 'loss: ': 4.792589262912148}\n",
      "{'epoch': 13, 'loss: ': 4.364009411711442}\n",
      "{'epoch': 14, 'loss: ': 4.0406886799293655}\n",
      "{'epoch': 15, 'loss: ': 3.8146101361826847}\n",
      "{'epoch': 16, 'loss: ': 3.6332992127067163}\n",
      "{'epoch': 17, 'loss: ': 3.4835236637215865}\n",
      "{'epoch': 18, 'loss: ': 3.3542638682482537}\n",
      "{'epoch': 19, 'loss: ': 3.219769099302459}\n"
     ]
    }
   ],
   "source": [
    "model = MyLSTMModel(len(pooh_dataset.uniq_words), device)\n",
    "model.to(device)\n",
    "# train(pooh_dataset, model)\n",
    "# torch.save(model.state_dict(), '/content/sample_data/pooh_3x512_20ep.model')\n",
    "# model.load_state_dict(torch.load('/home/maria/Documents/NLP/data/assignment_5/pooh_2x512_30ep.model'))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bPboVDnW0zW",
    "outputId": "59bdd347-b413-4a0d-92bf-02c324c5b62c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7858145171578007\n",
      "0.6540375047837734\n"
     ]
    }
   ],
   "source": [
    "reconstruction_1, prob_1 = reconstruct_sentence_1(model, test_dataset, pooh_dataset)\n",
    "reconstruction_2, prob_2 = reconstruct_sentence_2(model, test_dataset, pooh_dataset, words_to_remember=5)\n",
    "print(accuracy(test_dataset, reconstruction_1))\n",
    "print(accuracy(test_dataset, reconstruction_2))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deE7sxeCW0zW",
    "outputId": "5ecdadc8-232e-4046-c6f7-30c9ae0e21fc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [01:33<00:00,  4.67s/it]\n"
     ]
    }
   ],
   "source": [
    "best_text, best_p = sample_text(model, test_dataset, pooh_dataset, 20)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XWZmzo3CW0zX",
    "outputId": "ab2af83c-b8d9-4c30-f5c8-ae42eebf4e27"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7799464217374665"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "accuracy(test_dataset, best_text)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqDxsvLSW0zX",
    "outputId": "59549c0d-51f0-4e70-bcb5-7997e4365cc9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(best_p)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-CI3RLoaViR",
    "outputId": "ac553979-43dc-40c9-acf7-69179e2dac54"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-1401.2726\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "assignment_5_task_1.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}